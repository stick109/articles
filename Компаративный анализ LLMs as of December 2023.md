Мне тут надо было написать некий код именно на джаве (не спрашивайте), и я решил написать его на привычном С# и потом просто попросить LLM перевести его на джаву. Ну как просто - я думал, что просто, это же самые близкие друг другу языки, так? Ведь так?

Задачи производить компаративный анализ вначале у меня не стояло - нужен был только результат. И я начал с Claude, потому что в последнее время именно им пользовался больше всего, потому что мне нравится, как он ответы систематизирует в таблички лучше, что другие.

Код на C# у меня получился размером в 50 строк - потому что я люблю писать chained linq expressions, начиная каждый .Method с новой строки, для readability - это я говорю для проформы, чтобы вам было понятно, что код был не ахти сложный - так, medium.

Код на джаве получился процентов на 10-20 длиннее, на 30-40 менее читабельным, но главное, он не компилировался. Выглядел он, впрочем, как код, который в принципе может заработать, и я продолжил. Скормил error messages обратно, и получил следующую итерацию - ещё чуть длиннее, ещё чуть менее читабельную, и опять не компилируемую, но с другими ошибками. Когда не скомпилировалась и третья итерация (опять с другими ошибками), я плюнул и решил попробовать свою первую любовь ChatGPT.

Первая итерация ChatGPT не скомпилировалась, но с ещё более другими ошибками, чем были у Claude. Но со второй итерацией произошло чудо: она скомпилировалась и запустилась, в этот раз упав на runtime error совершенно обскурного вида: java.lang.NullPointerException: Cannot invoke "java.lang.reflect.Method.getGenericParameterTypes()" because "<local2>" is null

При этом сам код выглядел относительно нормально, никакого явного обращения к reflection - да и вообще, моя ли это задача разбираться в причинах ошибки. Поэтому я сообщил об ошибке чату гпт и получил третью итерацию - которая, к моему удивлению, произвела ту же самую ошибку рантайма.

Такая разница между LLMs меня заинтриговала, и я, уже в чисто исследовательских целях, а также вспомнив, что гугол только что анонсировал gemini, задал ту же задачу туда.

Результат (you guessed it) - compilation errors. В отличие от предыдущих двух LLMs, удобным для меня образом печатавших новый код целиком, так что мне только оставалось сделать copy-paste, gemini довольно пренебрежительно выдала только строчки, которые надо исправить - чтобы, значица, я сам тоже не ленился, а вручную искал, что именно тут надо вырезать и заменить на новый код. Needless to say, новый код не скомпилировался опять, и третью итерацию с этим хамлом я делать уж не стал.

И уже совсем решив заканчивать исследование, я вдруг вспомнил, что никогда ещё не использовал copilot.

Copilot же, засучив рукава, с первой попытки выдал мне код всего с одной ошибкой компиляции - да и та не прямо реальная ошибка, а скорее typo, он просто одинаково назвал две разные локальные переменные. Я даже не стал делать вторую итерацию, просто исправил in place, и вуаля! Код сразу заработал и сразу прошёл все юнит тесты.

Таким образом, ranking в этом конкретном исследовании выглядит так:
1. Copilot, с большим отрывом
2. Claude и ChatGPT, очень похожи, но не идентичны
3. Gemini, полное говно
